#!/usr/bin/env python3
"""
YAML Preprocessor for Scientific HTML Parser

This script takes the complex YAML front matter generated by the webhook_v3 service
and simplifies it to make it more easily parsable by n8n JavaScript processors.

It flattens nested structures, ensures consistent indentation, and reformats the content
according to the requirements for n8n integration.
"""

import os
import re
import json
import yaml
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

from ..config import settings

logger = logging.getLogger(__name__)
logger.setLevel(settings.LOG_LEVEL)

class YAMLPreprocessor:
    """
    Preprocess YAML front matter to make it more n8n-friendly by flattening structures
    and ensuring consistent formatting.
    """
    
    def __init__(self):
        """Initialize the preprocessor with configuration from environment variables."""
        self.output_dir = os.environ.get("OUTPUT_DIR", "output/md")
        self.save_local_files = os.environ.get("SAVE_LOCAL_FILES", "true").lower() in ("true", "1", "yes")
        self.convert_to_json = os.environ.get("CONVERT_TO_JSON", "false").lower() in ("true", "1", "yes")
    
    def process_file(self, filepath: str) -> bool:
        """
        Process a file containing YAML front matter.
        
        Args:
            filepath: Path to the file to process
            
        Returns:
            bool: True if processing was successful, False otherwise
        """
        try:
            file_path = Path(filepath)
            if not file_path.exists():
                logger.error(f"File not found: {filepath}")
                return False
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extract YAML front matter
            yaml_match = re.search(r'^---\n(.*?)\n---', content, re.DOTALL)
            if not yaml_match:
                logger.warning(f"No YAML front matter found in {filepath}")
                return False
            
            yaml_content = yaml_match.group(1)
            remaining_content = content[yaml_match.end():]
            
            # Parse YAML
            try:
                yaml_data = yaml.safe_load(yaml_content)
            except yaml.YAMLError as e:
                logger.error(f"Error parsing YAML: {e}")
                return False
            
            # Simplify and flatten the YAML structure
            simplified_data = self._simplify_yaml_structure(yaml_data)
            
            # Generate the output
            if self.convert_to_json:
                # JSON format
                simplified_json = json.dumps(simplified_data, indent=2)
                new_content = f"```json\n{simplified_json}\n```\n\n{remaining_content}"
                output_path = file_path.with_suffix('.json')
            else:
                # YAML format
                simplified_yaml = yaml.dump(simplified_data, sort_keys=False, default_flow_style=False, indent=2)
                new_content = f"---\n{simplified_yaml}---\n\n{remaining_content}"
                output_path = file_path.with_name(f"{file_path.stem}_simplified{file_path.suffix}")
            
            # Save to file
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            logger.info(f"Successfully processed {filepath} and saved to {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"Error processing file {filepath}: {e}")
            return False
    
    def process_yaml_string(self, yaml_content: str) -> Optional[str]:
        """
        Process a YAML string directly.
        
        Args:
            yaml_content: YAML content as a string
            
        Returns:
            Optional[str]: Simplified YAML content or None if processing failed
        """
        try:
            # Parse YAML
            yaml_data = yaml.safe_load(yaml_content)
            
            # Simplify and flatten the YAML structure
            simplified_data = self._simplify_yaml_structure(yaml_data)
            
            # Generate the output
            if self.convert_to_json:
                return json.dumps(simplified_data, indent=2)
            else:
                return yaml.dump(simplified_data, sort_keys=False, default_flow_style=False, indent=2)
        
        except Exception as e:
            logger.error(f"Error processing YAML string: {e}")
            return None
    
    def _simplify_yaml_structure(self, data: Dict) -> Dict:
        """
        Simplify and flatten the YAML structure according to requirements.
        
        Args:
            data: The parsed YAML data as a dictionary
            
        Returns:
            Dict: A simplified and flattened dictionary
        """
        simplified = {}
        
        # Basic metadata (direct key-value pairs)
        for key in ['title', 'source_url', 'date_processed', 'doi', 'publication_date', 'journal']:
            if key in data:
                simplified[key] = data[key]
        
        # Ensure consistent author formatting
        if 'authors' in data and isinstance(data['authors'], list):
            simplified['authors'] = data['authors']
            # Add a simple author citation if it doesn't exist
            if 'author_citation' not in data and simplified['authors']:
                simplified['author_citation'] = ', '.join(simplified['authors'])
        
        # Document type
        if 'document_type' in data:
            simplified['document_type'] = data['document_type']
        else:
            simplified['document_type'] = 'scientific_paper'
        
        # Process entities - flatten nested structures
        if 'entities' in data and isinstance(data['entities'], dict):
            entities = data['entities']
            
            # Physiological parameters
            if 'physiological_parameter' in entities:
                simplified['physiological_parameters'] = entities['physiological_parameter']
            
            # Body systems
            if 'body_system' in entities:
                simplified['body_systems'] = entities['body_system']
            
            # Exercise types
            if 'exercise_type' in entities:
                simplified['exercise_types'] = entities['exercise_type']
            
            # Heat therapy types
            if 'heat_therapy' in entities:
                simplified['heat_therapies'] = entities['heat_therapy']
            
            # Health outcomes
            if 'health_outcome' in entities:
                simplified['health_outcomes'] = entities['health_outcome']
            
            # Toxins
            if 'toxin' in entities:
                simplified['toxins'] = entities['toxin']
        
        # Process mechanisms - flatten into simple arrays
        if 'mechanisms' in data and isinstance(data['mechanisms'], dict):
            mechanisms = data['mechanisms']
            
            # Cellular mechanisms
            if 'cellular_mechanisms' in mechanisms:
                simplified['cellular_mechanisms'] = mechanisms['cellular_mechanisms']
            
            # Vascular mechanisms
            if 'vascular_mechanisms' in mechanisms:
                simplified['vascular_mechanisms'] = mechanisms['vascular_mechanisms']
            
            # Inflammatory mechanisms
            if 'inflammatory_mechanisms' in mechanisms:
                simplified['inflammatory_mechanisms'] = mechanisms['inflammatory_mechanisms']
        
        # Process study types - flatten to array
        if 'study_type' in data:
            simplified['study_types'] = data['study_type']
        
        # Process therapeutic domains - flatten to array
        if 'therapeutic_domains' in data:
            simplified['therapeutic_domains'] = data['therapeutic_domains']
        
        # Process sections - keep as array of objects with consistent properties
        if 'sections' in data and isinstance(data['sections'], dict):
            simplified_sections = []
            for section_id, section_data in data['sections'].items():
                simplified_section = {
                    'id': section_id,
                    'heading': section_data.get('heading', ''),
                    'keywords': section_data.get('keywords', [])
                }
                simplified_sections.append(simplified_section)
            
            simplified['sections'] = simplified_sections
        
        # Add metadata for parsing
        simplified['schema_version'] = '1.1.0'  # Match app version
        simplified['processed_date'] = datetime.now().isoformat()
        
        return simplified
    
    def process_directory(self, dirpath: str) -> int:
        """
        Process all YAML files in a directory.
        
        Args:
            dirpath: Path to directory containing files
            
        Returns:
            int: Number of files successfully processed
        """
        dir_path = Path(dirpath)
        if not dir_path.exists() or not dir_path.is_dir():
            logger.error(f"Directory not found: {dirpath}")
            return 0
        
        count = 0
        # Process MD files that might have YAML front matter
        for file_path in dir_path.glob("**/*.md"):
            if self.process_file(str(file_path)):
                count += 1
        
        return count

# Example usage if run directly
if __name__ == "__main__":
    import sys
    
    preprocessor = YAMLPreprocessor()
    
    if len(sys.argv) > 1:
        target = sys.argv[1]
        path = Path(target)
        
        if path.is_file():
            success = preprocessor.process_file(target)
            print(f"Processing file {'succeeded' if success else 'failed'}")
        elif path.is_dir():
            count = preprocessor.process_directory(target)
            print(f"Processed {count} files in directory {target}")
        else:
            print(f"Path not found: {target}")
    else:
        print("Usage: python -m app.services.yaml_preprocessor <file_or_directory>") 